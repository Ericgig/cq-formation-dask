{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20de159e-3124-46c1-86c5-a0632addaf48",
   "metadata": {},
   "source": [
    "Array traps and optimisation\n",
    "============================\n",
    "\n",
    "First let's start 3 workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224eb7dd-149c-4452-8080-d66d89c7a2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "from dask.distributed import Client, progress\n",
    "client = Client(\n",
    "    processes=False,\n",
    "    n_workers=3,\n",
    "    threads_per_worker=2,\n",
    ")\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f00e9d5-a90b-423a-b523-0fc4c8d9aaf8",
   "metadata": {},
   "source": [
    "Chunks size\n",
    "-----------\n",
    "\n",
    "- Too large chunks don't split work efficiently.\n",
    "- Too small and too much time is lost in communication and other overheads.\n",
    "- 100Mb~1Gb per chunks is usually good. Scheduling a single task take arround ~1ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df923b25-c7f1-4b51-8f38-3495fbae401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1 chunk\")\n",
    "arr = da.random.random((6000, 6000), chunks=(6000, 6000))\n",
    "%time x = arr.sum().compute()\n",
    "print(\"3 chunks\")\n",
    "arr = da.random.random((6000, 6000), chunks=(2000, 6000))\n",
    "%time x = arr.sum().compute()\n",
    "print(\"4 chunks\")\n",
    "arr = da.random.random((6000, 6000), chunks=(3000, 3000))\n",
    "%time x = arr.sum().compute()\n",
    "print(\"36 chunks\")\n",
    "arr = da.random.random((6000, 6000), chunks=(1000, 1000))\n",
    "%time x = arr.sum().compute()\n",
    "print(\"400 chunks\")\n",
    "arr = da.random.random((6000, 6000), chunks=(300, 300))\n",
    "%time x = arr.sum().compute()\n",
    "print(\"auto\")\n",
    "arr = da.random.random((6000, 6000), chunks=\"auto\")\n",
    "%time x = arr.sum().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8982c902-0191-4823-a109-6b88e690b168",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249041aa-174f-4469-9cf0-6d09a61486c2",
   "metadata": {},
   "source": [
    "Operation order\n",
    "---------------\n",
    "\n",
    "Dask has a symbolic tree of operation, but little tools for optimization.  \n",
    "It does not reorder operations for faster computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a19d02a-90db-4896-bb06-d1c15f7351cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = da.random.random((3000, 3000), chunks=(1000, 1000))\n",
    "B = da.random.random((3000, 3000), chunks=(1000, 1000))\n",
    "v = da.random.random((3000, 1), chunks=(1000, 1))\n",
    "MM1 = (A @ B) @ v\n",
    "MM2 = A @ (B @ v)\n",
    "%time MM1.compute()\n",
    "%time MM2.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11579bfd-b503-48f5-8bb7-e26e900f9ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# einsum can do operation in the right order, but the operation is not optimized\n",
    "einMM = da.einsum(\"ij,jk,kl->il\", A, B, v)\n",
    "%time einMM.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8191d07-3c1e-42c7-93b0-4c355c58455c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dask",
   "language": "python",
   "name": "dask"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
